{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fdaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Embedding, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_glove_vectors(filename=\"data/glove.6B.100d.txt\"):\n",
    "    ## function from https://campus.datacamp.com/courses/recurrent-neural-networks-for-language-modeling-in-python/rnn-architecture?ex=7\n",
    "    # Get all word vectors from pre-trained model\n",
    "    glove_vector_dict = {}\n",
    "    with open(filename, encoding=\"UTF-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = values[1:]\n",
    "            glove_vector_dict[word] = np.asarray(coefs, dtype='float32')\n",
    "    return glove_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ffd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f388bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed seconds = 10.228618621826172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "glove_vector_dict = get_glove_vectors()\n",
    "\n",
    "end = time.time()\n",
    "print(f'elapsed seconds = {end - start}')\n",
    "type(glove_vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8fd193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vector_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12aa17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe279cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33202f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id              keyword   location  \\\n",
      "161  232  airplane%20accident  Havenford   \n",
      "\n",
      "                                                  text  target  \n",
      "161  + Nicole Fletcher one of a victim of crashed a...       1  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"+ Nicole Fletcher one of a victim of crashed airplane few times ago. \\n\\nThe accident left a little bit trauma for her. Although she's \\n\\n+\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = df_train[df_train['id']==232]\n",
    "print(s1)\n",
    "s2 = df_train.iloc[161,3]\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e686805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4296597924602653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].agg(sum)/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3df2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_up_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Clean up the content of one tweet, removing punctuation and numbers. \n",
    "    \n",
    "    Parameters:\n",
    "    tweet(str):The text of the tweet\n",
    "    \n",
    "    Returns:\n",
    "    word_list: A list of pure alphabetic words in lower case\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Remove all characters execept alphabetic chars and space,\n",
    "    ## convert to lower case and split on space.\n",
    "    word_list = re.sub('[^A-Za-z ]+','',tweet).lower().split(' ')\n",
    "    return word_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73066b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'nicole',\n",
       " 'fletcher',\n",
       " 'one',\n",
       " 'of',\n",
       " 'a',\n",
       " 'victim',\n",
       " 'of',\n",
       " 'crashed',\n",
       " 'airplane',\n",
       " 'few',\n",
       " 'times',\n",
       " 'ago',\n",
       " 'the',\n",
       " 'accident',\n",
       " 'left',\n",
       " 'a',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'trauma',\n",
       " 'for',\n",
       " 'her',\n",
       " 'although',\n",
       " 'shes',\n",
       " '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_up_tweet(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5ddcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [just, happened, a, terrible, car, crash]\n",
       "1    [heard, about, earthquake, is, different, citi...\n",
       "2    [there, is, a, forest, fire, at, spot, pond, g...\n",
       "3           [apocalypse, lighting, spokane, wildfires]\n",
       "4    [typhoon, soudelor, kills, , in, china, and, t...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text'].head().map(clean_up_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7d4e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Just happened a terrible car crash\n",
       "1    Heard about #earthquake is different cities, s...\n",
       "2    there is a forest fire at spot pond, geese are...\n",
       "3             Apocalypse lighting. #Spokane #wildfires\n",
       "4        Typhoon Soudelor kills 28 in China and Taiwan\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5bd2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 5)\n",
      "(1523, 5)\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(df_train, train_size=0.8, shuffle=True, random_state=42)\n",
    "print(train.shape)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca604cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090,)\n",
      "(1523,)\n",
      "(3263,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train['text'].map(clean_up_tweet)\n",
    "valid_x = valid['text'].map(clean_up_tweet)\n",
    "test_x = df_test['text'].map(clean_up_tweet)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdbf7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 1. 1.]\n",
      "0.43054187192118226\n",
      "0.4261326329612607\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array(train['target'], dtype=np.float32)\n",
    "valid_y = np.array(valid['target'], dtype=np.float32)\n",
    "print(train_y[:5])\n",
    "print(train_y[-5:])\n",
    "print(np.sum(train_y)/len(train_y))\n",
    "print(np.sum(valid_y)/len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "88ea7045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6451445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "30\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "train['tweet_word_counts'] = [len(x) for x in train_x]\n",
    "valid['tweet_word_counts'] = [len(x) for x in valid_x]\n",
    "df_test['tweet_word_counts'] = [len(x) for x in test_x]\n",
    "print(np.max(train['tweet_word_counts']) )\n",
    "print(np.max(valid['tweet_word_counts']) )\n",
    "print(np.max(df_test['tweet_word_counts']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "829f217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57835 , -0.079743,  0.23589 ,  0.14232 , -0.74898 ,  0.091366,\n",
       "        -0.14814 , -0.14615 , -0.68526 ,  0.31882 , -0.56023 , -0.057425,\n",
       "         0.14159 , -0.072444,  0.61525 , -0.50256 ,  0.42331 , -0.76756 ,\n",
       "         0.51353 , -0.39777 ,  0.38048 ,  0.4395  ,  0.73211 ,  0.28665 ,\n",
       "        -0.32091 , -0.52521 , -0.54786 ,  0.31282 , -0.027817,  0.89241 ,\n",
       "         0.91175 ,  0.13016 , -0.6932  , -0.23235 ,  1.2732  ,  0.033154,\n",
       "         0.5625  ,  0.26646 , -0.29519 , -1.2666  , -0.029055, -0.31218 ,\n",
       "        -0.32454 , -0.3499  , -0.015618, -0.39364 , -0.37477 ,  0.27252 ,\n",
       "        -1.3312  , -1.0447  ,  0.47559 , -0.23485 ,  0.1743  ,  0.68365 ,\n",
       "        -0.40499 , -1.8036  ,  0.2963  , -0.070282,  1.471   , -0.20166 ,\n",
       "         0.045613, -0.34433 , -0.32697 ,  0.15731 ,  0.9668  , -0.051295,\n",
       "        -0.12976 ,  0.55869 , -0.20778 , -0.10335 , -0.015856, -0.78811 ,\n",
       "         0.24645 ,  0.18674 ,  0.2534  , -0.7372  , -0.14293 , -0.74162 ,\n",
       "         0.1976  , -0.63874 ,  0.040931,  0.043692, -0.39629 ,  0.57154 ,\n",
       "         0.007759,  0.34247 , -0.42337 ,  0.67995 ,  0.50617 , -0.7667  ,\n",
       "        -0.89381 , -0.18882 , -0.1583  , -0.37053 ,  0.42761 ,  0.73701 ,\n",
       "        -0.25237 ,  0.35373 , -0.8653  ,  0.80499 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral = glove_vector_dict[\"neutral\"]\n",
    "placeHolder = np.array([neutral])\n",
    "placeHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0163932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_word_embeddings(word_lists, pad_to=54):\n",
    "    ## We plan to replace all the words in the tweets\n",
    "    ## with embeddings from the GloVe dictionary, skipping\n",
    "    ## any words not found, and also padding the sequence \n",
    "    ## of embeddings to a fixed length.\n",
    "    \n",
    "    ## If none of the words match for a given tweet we will substitute\n",
    "    ## a with place holder vector of one word, \"neutral\".\n",
    "    d = glove_vector_dict\n",
    "    neutral = d[\"neutral\"]\n",
    "    placeHolder = np.array([neutral])\n",
    "    padNeutral = pad_sequences(placeHolder.T, pad_to, dtype='float32')\n",
    "    ## print('padNeutral',padNeutral)\n",
    "    outer = []\n",
    "    for word_list in word_lists:\n",
    "        enc_list = []\n",
    "        for word in word_list:\n",
    "            ## print(word)\n",
    "            if(type(d.get(word)) is np.ndarray):\n",
    "                enc_list.append(d.get(word))\n",
    "                ## print(d.get(word))\n",
    "        if(len(enc_list) > 0):\n",
    "            enc_array = np.array(enc_list)\n",
    "#             print('shape: ',enc_array.shape)\n",
    "#             print('enc_array = ',enc_array)\n",
    "#             print('enc_array.T', enc_array.T)\n",
    "            pad = pad_sequences(enc_array.T, pad_to, dtype='float32')\n",
    "#             print('pad',pad)\n",
    "            outer.append(pad.T)\n",
    "#             print('outer shape',outer.shape)\n",
    "#             print('outer', outer)\n",
    "        else:\n",
    "            outer.append(padNeutral.T)\n",
    "    return np.array(outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4ec3bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090,)\n",
      "(1523,)\n",
      "(3263,)\n"
     ]
    }
   ],
   "source": [
    "print (train_x.shape)\n",
    "print (valid_x.shape)\n",
    "print (test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45652d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8abe8196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed seconds = 2.5990195274353027\n",
      "(6090, 54, 100)\n",
      "(1523, 54, 100)\n",
      "(3263, 54, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "X_train = glove_word_embeddings(train_x)\n",
    "X_valid = glove_word_embeddings(valid_x)\n",
    "X_test = glove_word_embeddings(test_x)\n",
    "end = time.time()\n",
    "print(f'elapsed seconds = {end - start}')\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56dc274c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32314  , -0.28602  ,  0.25893  ,  0.47132  , -0.18749  ,\n",
       "        0.27926  , -0.031222 , -0.36132  ,  0.31671  ,  0.23897  ,\n",
       "        0.64852  ,  1.1412   ,  0.024164 ,  0.35895  ,  0.32754  ,\n",
       "       -0.25261  ,  0.50337  , -0.45188  , -1.119    , -0.37694  ,\n",
       "        1.0946   , -0.99613  , -0.027026 , -0.38558  , -0.2442   ,\n",
       "        0.6179   , -0.25935  , -0.23036  ,  1.017    , -0.63974  ,\n",
       "        0.13511  , -0.39997  , -0.33846  , -0.22887  ,  0.43298  ,\n",
       "        0.12857  ,  0.77761  , -0.70721  ,  0.064632 , -0.60949  ,\n",
       "       -0.11196  ,  0.32177  ,  1.2263   , -0.14458  ,  0.37544  ,\n",
       "       -0.48593  ,  0.11136  ,  0.064378 ,  0.15517  , -0.55285  ,\n",
       "        0.047002 ,  0.19373  ,  0.21567  ,  0.80757  ,  0.22276  ,\n",
       "       -0.49492  ,  0.24592  , -0.96245  ,  1.3597   ,  0.083068 ,\n",
       "        0.13025  ,  0.39716  , -0.66914  , -0.76966  ,  0.51586  ,\n",
       "       -0.68805  , -0.1597   ,  0.89775  , -0.8484   ,  0.16297  ,\n",
       "       -0.50192  , -0.74355  , -0.36056  , -0.92933  , -0.37152  ,\n",
       "        0.59955  , -0.61441  , -0.2418   , -0.61913  ,  0.24565  ,\n",
       "        1.006    , -0.27913  , -0.26987  ,  0.39665  , -0.71298  ,\n",
       "        0.13516  ,  0.53521  , -0.043937 ,  0.5575   ,  0.42296  ,\n",
       "       -0.16794  , -0.65506  ,  0.35106  ,  0.64099  , -0.7918   ,\n",
       "       -0.50021  ,  0.14867  ,  0.47441  , -0.0056446], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,53,0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff34bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, None, 128)         88320     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, None, 128)         99072     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,593\n",
      "Trainable params: 286,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DROPOUT = 0.2\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(GRU(units=128, input_shape=(None, 100), return_sequences=True, dropout=DROPOUT))\n",
    "model.add(GRU(units=128, return_sequences=True, dropout=DROPOUT))\n",
    "model.add(GRU(units=128, return_sequences=False, dropout=DROPOUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "file_name = 'weights_{epoch:03d}_{val_accuracy:.4f}.hdf5'\n",
    "\n",
    "checkpoint_filepath = os.path.join('.', 'SAVE_MODELS', file_name)\n",
    "\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=6, restore_best_weights=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "914480ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "305/305 [==============================] - 11s 20ms/step - loss: 0.4991 - accuracy: 0.7691 - val_loss: 0.4312 - val_accuracy: 0.8089\n",
      "Epoch 2/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.4410 - accuracy: 0.8030 - val_loss: 0.4310 - val_accuracy: 0.8188\n",
      "Epoch 3/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.4294 - accuracy: 0.8079 - val_loss: 0.4251 - val_accuracy: 0.8175\n",
      "Epoch 4/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.4082 - accuracy: 0.8240 - val_loss: 0.4450 - val_accuracy: 0.7991\n",
      "Epoch 5/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.4031 - accuracy: 0.8264 - val_loss: 0.4215 - val_accuracy: 0.8142\n",
      "Epoch 6/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.3800 - accuracy: 0.8369 - val_loss: 0.4378 - val_accuracy: 0.8135\n",
      "Epoch 7/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.3628 - accuracy: 0.8414 - val_loss: 0.4405 - val_accuracy: 0.8142\n",
      "Epoch 8/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.3415 - accuracy: 0.8565 - val_loss: 0.4455 - val_accuracy: 0.8102\n",
      "Epoch 9/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.3240 - accuracy: 0.8631 - val_loss: 0.4840 - val_accuracy: 0.8037\n",
      "Epoch 10/100\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.3018 - accuracy: 0.8741 - val_loss: 0.5014 - val_accuracy: 0.7938\n",
      "Epoch 11/100\n",
      "304/305 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.8877Restoring model weights from the end of the best epoch: 5.\n",
      "305/305 [==============================] - 5s 17ms/step - loss: 0.2791 - accuracy: 0.8877 - val_loss: 0.5394 - val_accuracy: 0.7951\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, train_y, \n",
    "                    batch_size=20, \n",
    "                    epochs=100, \n",
    "                    validation_data=(X_valid,valid_y),\n",
    "                    callbacks=[earlyStopping,modelCheckpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68ff4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set aside full data set for retraining for competition\n",
    "## see if training on the full training set improves results\n",
    "\n",
    "full_x = df_train['text'].map(clean_up_tweet)\n",
    "full_y = np.array(df_train['target'], dtype=np.float32)\n",
    "X_full = glove_word_embeddings(full_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b791a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 6s 17ms/step - loss: 0.3904 - accuracy: 0.8341\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 6s 16ms/step - loss: 0.3809 - accuracy: 0.8404\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - 6s 16ms/step - loss: 0.3642 - accuracy: 0.8464\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 6s 16ms/step - loss: 0.3520 - accuracy: 0.8521\n",
      "Epoch 5/5\n",
      "381/381 [==============================] - 6s 16ms/step - loss: 0.3378 - accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_full, full_y, \n",
    "                    batch_size=20, \n",
    "                    epochs=5, \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4b904ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       0\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_num = 3\n",
    "\n",
    "predict_proba = model.predict(X_test,batch_size=20)\n",
    "predict = (predict_proba > 0.5).astype(int)\n",
    "\n",
    "# predict2 = np.reshape(predict,len(predict),)\n",
    "# predict2\n",
    "\n",
    "submission = pd.DataFrame(df_test['id'])\n",
    "submission['target']=predict\n",
    "\n",
    "submission.to_csv(f'data/submission{sub_num}.csv',index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab4bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
